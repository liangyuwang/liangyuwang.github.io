---
title: "ZO2: Scalable Zeroth-Order Fine-Tuning for Extremely Large Language Models with Limited GPU Memory"
collection: publications
category: conferences
permalink: /publication/2024-03-01-zo2
excerpt: 'A framework that enables fine-tuning of extremely large language models on limited GPU memory through zeroth-order optimization and CPU-GPU offloading.'
date: 2025-03-16
venue: 'NeurIPS workshop, 2024; arXiv preprint'
paperurl: 'https://arxiv.org/abs/2503.12668'
codeurl: 'https://github.com/liangyuwang/zo2'
citation: 'Liangyu Wang, Jie Ren, Hang Xu, Junxiao Wang, Huanyi Xie, David E. Keyes, and Di Wang. (2025). &quot;ZO2: Scalable Zeroth-Order Fine-Tuning for Extremely Large Language Models with Limited GPU Memory.&quot; <i>arXiv preprint arXiv:2503.12668</i>'
---

[Download paper here](https://arxiv.org/abs/2503.12668)

[Download code here](https://github.com/liangyuwang/zo2) 